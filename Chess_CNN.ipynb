{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Chess CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhammadBadawy/CS231/blob/master/Chess_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhpY_1mfK1qB",
        "colab_type": "text"
      },
      "source": [
        "# Chess classifier (using CNN and data augmentation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuIfqPw4K1qH",
        "colab_type": "text"
      },
      "source": [
        "First let's start by importing the main libraries that we will need in our project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkCzaOIqK1q9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# and for visualization\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsRXlMF5K1rY",
        "colab_type": "text"
      },
      "source": [
        "Now we start the EDA, we need to see what our data looks like\n",
        "\n",
        "1. The number of samples\n",
        "2. The distribution of samples between classes\n",
        "3. quality of the images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmva5hQ5K1rc",
        "colab_type": "text"
      },
      "source": [
        "let's scan our directory to get the labels from the folder names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YK4qnGZK1re",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We need os library to handle the pathes and directories\n",
        "import os\n",
        "\n",
        "folder_name = 'drive/My Drive/chess/Chess'\n",
        "chess_folders = os.listdir(folder_name)\n",
        "\n",
        "chess_pieces = {}\n",
        "for piece in chess_folders:\n",
        "    chess_pieces[piece] = len(os.listdir(\"drive/My Drive/chess/Chess/\"+piece))\n",
        "    \n",
        "print(chess_pieces)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uu7Mc85lK1rv",
        "colab_type": "text"
      },
      "source": [
        "As we are seeing\n",
        "\n",
        "1. The data samples are few\n",
        "2. They are not that poorly distributed between classes\n",
        "\n",
        "Let's make a visualization to make it more clear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7Im975fK1rz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(14, 6))\n",
        "plt.bar(range(len(chess_pieces)), list(chess_pieces.values()), color=\"purple\")\n",
        "plt.xticks(range(len(chess_pieces)), list(chess_pieces))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsnEdqBQpw2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kQrovDxK1tP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=30,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.05,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "\n",
        "for piece in chess_folders:\n",
        "    piece_images = os.listdir(\"drive/My Drive/chess/Chess/\"+piece)\n",
        "    \n",
        "    for image in piece_images:\n",
        "        image_name = image.split(\".\")[0]\n",
        "        img = load_img('drive/My Drive/chess/Chess'+'/'+piece+'/'+image)\n",
        "        x = img_to_array(img)\n",
        "        x = x.reshape((1,) + x.shape)\n",
        "\n",
        "\n",
        "        i = 0\n",
        "        for batch in datagen.flow(x, batch_size=1,\n",
        "                                  save_to_dir='drive/My Drive/chess/pieces'+'/'+piece, save_prefix=piece+\"_\"+image_name, save_format='jpeg'):\n",
        "            i += 1\n",
        "            if i > 4:\n",
        "                break  # otherwise the generator would loop indefinitely\n",
        "\n",
        "\n",
        "\n",
        "# img = load_img('Chess/Pawn/00000035.jpg')\n",
        "# x = img_to_array(img)\n",
        "# x = x.reshape((1,) + x.shape)\n",
        "\n",
        "\n",
        "# i = 0\n",
        "# for batch in datagen.flow(x, batch_size=1,\n",
        "#                           save_to_dir='preview', save_prefix='cat', save_format='jpeg'):\n",
        "#     i += 1\n",
        "#     if i > 20:\n",
        "#         break  # otherwise the generator would loop indefinitely"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Smd8xAfK1td",
        "colab_type": "text"
      },
      "source": [
        "now after data augmentation let's check the data again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlwXudoZK1th",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chess_pieces = {}\n",
        "for piece in chess_folders:\n",
        "    chess_pieces[piece] = len(os.listdir(\"drive/My Drive/chess/pieces/\"+piece))\n",
        "    \n",
        "print(chess_pieces)\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.bar(range(len(chess_pieces)), list(chess_pieces.values()), color=\"purple\")\n",
        "plt.xticks(range(len(chess_pieces)), list(chess_pieces))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvHCVnoRK1tv",
        "colab_type": "text"
      },
      "source": [
        "Now we got more data with accepted samples per class, Let's start the pre processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JhhbmqdK1tx",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing steps:\n",
        "\n",
        "1. Let's grayscale the images, because colors aren't realy good features to classify a chess piece\n",
        "2. Resize the images to a fixed size to feed it to the the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h4apsaRK1t0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "input_shape = (300, 300, 1)\n",
        "batch_size = 16\n",
        "\n",
        "training_generator = train_datagen.flow_from_directory(\n",
        "    'drive/My Drive/chess/pieces',\n",
        "    target_size=(300, 300),\n",
        "    color_mode='grayscale',\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "#     subset='training',\n",
        "    shuffle=True, #we shuffle our images for better performance\n",
        "    seed=8)\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    'drive/My Drive/chess/testing',\n",
        "    target_size=(300, 300),\n",
        "    color_mode='grayscale',\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "#     subset='validation',\n",
        "    shuffle=True,\n",
        "    seed=7)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tur9pd26K1t9",
        "colab_type": "text"
      },
      "source": [
        "Now it's time to build our neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i75H9ShkK1t-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, Activation, BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiayEWUwK1uJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "  Conv2D(16, (5, 5), input_shape=input_shape, padding='same', activation='relu'),\n",
        "  Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
        "  MaxPool2D((2, 2)),\n",
        "  Dropout(0.2),\n",
        "  Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "  Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "  MaxPool2D((2, 2)),\n",
        "  Dropout(0.2),\n",
        "  Flatten(),\n",
        "  Dense(128, activation='relu'),\n",
        "  Dropout(0.2),\n",
        "  Dense(6, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEz3MiSwK1uU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5rwhia-K1ud",
        "colab_type": "text"
      },
      "source": [
        "Now we train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWjORhwMK1ug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(\n",
        "        training_generator,\n",
        "        steps_per_epoch=25,\n",
        "        epochs=20,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHGs9i0HWQ5V",
        "colab_type": "text"
      },
      "source": [
        "I trained the model many times and found that 20 epochs are good enough and doesn't cause over-fitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roU111AAWUWM",
        "colab_type": "text"
      },
      "source": [
        "Now let's see how the training went, and the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdfDnpG_K1u0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdnz-jKpj_bu",
        "colab_type": "text"
      },
      "source": [
        "Let's evauluate the model with some well known measures such as accuracy, recall, precision and f1 score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9Kl7PeAcETn",
        "colab_type": "text"
      },
      "source": [
        "Now let's see the results in more details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcA3pPesOLJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_of_test_samples = 122\n",
        "# Confution Matrix and Classification Report\n",
        "Y_pred = model.predict_generator(validation_generator, num_of_test_samples // batch_size + 1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "matrix1 = confusion_matrix(validation_generator.classes, y_pred)\n",
        "\n",
        "sns.heatmap(matrix1, annot=True, cbar=False);\n",
        "plt.ylabel('True Label');\n",
        "plt.xlabel('Predicted Label');\n",
        "plt.title('Confusion Matrix');\n",
        "plt.show()\n",
        "\n",
        "print('\\nClassification Report')\n",
        "target_names = ['Bishop',\n",
        "'King',\n",
        "'Rook',\n",
        "'Pawn',\n",
        "'Queen',\n",
        "'Knight']\n",
        "class_report = classification_report(validation_generator.classes, y_pred, target_names=target_names)\n",
        "print(class_report)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}